{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d089176d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-23T09:21:55.960536Z",
     "iopub.status.busy": "2023-05-23T09:21:55.960095Z",
     "iopub.status.idle": "2023-05-23T09:21:55.972509Z",
     "shell.execute_reply": "2023-05-23T09:21:55.971217Z"
    },
    "papermill": {
     "duration": 0.028796,
     "end_time": "2023-05-23T09:21:55.975672",
     "exception": false,
     "start_time": "2023-05-23T09:21:55.946876",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "text = [\"London Paris London\",\"Paris Paris London\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86e8db5d",
   "metadata": {
    "papermill": {
     "duration": 0.010028,
     "end_time": "2023-05-23T09:21:55.995941",
     "exception": false,
     "start_time": "2023-05-23T09:21:55.985913",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Now, we need to find a way to represent these texts as vectors. The `CountVectorizer()` class from `sklearn.feature_extraction.text` library can do this for us. We need to import this library before we can create a new `CountVectorizer()` object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "66da35f5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-23T09:21:56.018754Z",
     "iopub.status.busy": "2023-05-23T09:21:56.018320Z",
     "iopub.status.idle": "2023-05-23T09:21:57.221682Z",
     "shell.execute_reply": "2023-05-23T09:21:57.220146Z"
    },
    "papermill": {
     "duration": 1.218371,
     "end_time": "2023-05-23T09:21:57.225059",
     "exception": false,
     "start_time": "2023-05-23T09:21:56.006688",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "cv = CountVectorizer()\n",
    "count_matrix = cv.fit_transform(text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eeac5452",
   "metadata": {
    "papermill": {
     "duration": 0.010671,
     "end_time": "2023-05-23T09:21:57.246017",
     "exception": false,
     "start_time": "2023-05-23T09:21:57.235346",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "`count_matrix` gives us a sparse matrix. To make it in human readable form, we need to apply `toarrray()` method over it. And before printing out this `count_matrix`, let us first print out the feature list(or, word list), which have been fed to our `CountVectorizer()` object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fdca87c7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-23T09:21:57.268737Z",
     "iopub.status.busy": "2023-05-23T09:21:57.268324Z",
     "iopub.status.idle": "2023-05-23T09:21:57.276101Z",
     "shell.execute_reply": "2023-05-23T09:21:57.274862Z"
    },
    "papermill": {
     "duration": 0.02422,
     "end_time": "2023-05-23T09:21:57.280616",
     "exception": false,
     "start_time": "2023-05-23T09:21:57.256396",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['london', 'paris']\n",
      "[[2 1]\n",
      " [1 2]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function get_feature_names is deprecated; get_feature_names is deprecated in 1.0 and will be removed in 1.2. Please use get_feature_names_out instead.\n",
      "  warnings.warn(msg, category=FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "print(cv.get_feature_names())\n",
    "print(count_matrix.toarray())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ad2e7bd",
   "metadata": {
    "papermill": {
     "duration": 0.00985,
     "end_time": "2023-05-23T09:21:57.301190",
     "exception": false,
     "start_time": "2023-05-23T09:21:57.291340",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "This indicates that the word ‘london’ occurs 2 times in A and 1 time in B. Similarly, the word ‘paris’ occurs 1 time in A and 2 times in B. Makes sense. Right?\n",
    "\n",
    "Now, we need to find cosine(or “cos”) similarity between these vectors to find out how similar they are from each other. We can calculate this using `cosine_similarity()` function from `sklearn.metrics.pairwise` library."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4c3da02b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-23T09:21:57.325073Z",
     "iopub.status.busy": "2023-05-23T09:21:57.324622Z",
     "iopub.status.idle": "2023-05-23T09:21:57.394984Z",
     "shell.execute_reply": "2023-05-23T09:21:57.393591Z"
    },
    "papermill": {
     "duration": 0.086454,
     "end_time": "2023-05-23T09:21:57.397928",
     "exception": false,
     "start_time": "2023-05-23T09:21:57.311474",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1.  0.8]\n",
      " [0.8 1. ]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "similarity_scores = cosine_similarity(count_matrix)\n",
    "print(similarity_scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45d1e84c",
   "metadata": {
    "papermill": {
     "duration": 0.010343,
     "end_time": "2023-05-23T09:21:57.419632",
     "exception": false,
     "start_time": "2023-05-23T09:21:57.409289",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "What does this output indicate?\n",
    "\n",
    "We can interpret this output like this-\n",
    "\n",
    "1. Each row of the similarity matrix indicates each sentence of our input. So, row 0 = Text A and row 1 = Text B.\n",
    "2. The same thing applies for columns. To get a better understanding over this, we can say that the output given above is same as the following:\n",
    "\n",
    "<code>\n",
    "        Text A:     Text B:\n",
    "Text A: [[1.         0.8]  \n",
    "Text B: [0.8         1.]]  \n",
    "</code>\n",
    "<br>\n",
    "Interpreting this, says that Text A is similar to Text A(itself) by 100%(position [0,0]) and Text A is similar to Text B by 80%(position [0,1]). And by looking at the kind of output it is giving, we can easily say that this is always going to output a symmetric matrix. Because, if Text A is similar to Text B by 80% then, Text B is also going to be similar to Text A by 80%.\n",
    "\n",
    "\n",
    "Now we know how to find similarity between contents. So, let’s try to apply this knowledge to build a content based movie recommendation engine.\n",
    "\n",
    "### Building the recommendation engine:\n",
    "\n",
    ">The movie dataset that we are going to use in our recommendation engine can be downloaded from [Course Github Repo](https://github.com/codeheroku/Introduction-to-Machine-Learning/blob/master/Building%20a%20Movie%20Recommendation%20Engine/movie_dataset.csv).\n",
    "\n",
    "After downloading the dataset, we need to import all the required libraries and then read the csv file using `read_csv()` method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c86c0264",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-23T09:21:57.442297Z",
     "iopub.status.busy": "2023-05-23T09:21:57.441836Z",
     "iopub.status.idle": "2023-05-23T09:21:58.161162Z",
     "shell.execute_reply": "2023-05-23T09:21:58.159761Z"
    },
    "papermill": {
     "duration": 0.734321,
     "end_time": "2023-05-23T09:21:58.164311",
     "exception": false,
     "start_time": "2023-05-23T09:21:57.429990",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "df = pd.read_csv(\"/kaggle/input/movie-recommendation-system-sppu-2019/movie_dataset.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d0507f3",
   "metadata": {
    "papermill": {
     "duration": 0.010281,
     "end_time": "2023-05-23T09:21:58.184905",
     "exception": false,
     "start_time": "2023-05-23T09:21:58.174624",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "If you visualize the dataset, you will see that it has many extra info about a movie. We don’t need all of them. So, we choose keywords, cast, genres and director column to use as our feature set(the so called “content” of the movie)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "14f11128",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-23T09:21:58.209186Z",
     "iopub.status.busy": "2023-05-23T09:21:58.208587Z",
     "iopub.status.idle": "2023-05-23T09:21:58.215871Z",
     "shell.execute_reply": "2023-05-23T09:21:58.214918Z"
    },
    "papermill": {
     "duration": 0.023,
     "end_time": "2023-05-23T09:21:58.218707",
     "exception": false,
     "start_time": "2023-05-23T09:21:58.195707",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "features = ['keywords','cast','genres','director']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8c2f1fa",
   "metadata": {
    "papermill": {
     "duration": 0.009842,
     "end_time": "2023-05-23T09:21:58.238864",
     "exception": false,
     "start_time": "2023-05-23T09:21:58.229022",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Our next task is to create a function for combining the values of these columns into a single string."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e4696210",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-23T09:21:58.262471Z",
     "iopub.status.busy": "2023-05-23T09:21:58.261701Z",
     "iopub.status.idle": "2023-05-23T09:21:58.267179Z",
     "shell.execute_reply": "2023-05-23T09:21:58.266189Z"
    },
    "papermill": {
     "duration": 0.020107,
     "end_time": "2023-05-23T09:21:58.269820",
     "exception": false,
     "start_time": "2023-05-23T09:21:58.249713",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def combine_features(row):\n",
    "    return row['keywords']+\" \"+row['cast']+\" \"+row['genres']+\" \"+row['director']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4464da35",
   "metadata": {
    "papermill": {
     "duration": 0.010233,
     "end_time": "2023-05-23T09:21:58.290230",
     "exception": false,
     "start_time": "2023-05-23T09:21:58.279997",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Now, we need to call this function over each row of our dataframe. But, before doing that, we need to clean and preprocess the data for our use. We will fill all the NaN values with blank string in the dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3db8595d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-23T09:21:58.314260Z",
     "iopub.status.busy": "2023-05-23T09:21:58.313499Z",
     "iopub.status.idle": "2023-05-23T09:21:58.518189Z",
     "shell.execute_reply": "2023-05-23T09:21:58.517113Z"
    },
    "papermill": {
     "duration": 0.220336,
     "end_time": "2023-05-23T09:21:58.521184",
     "exception": false,
     "start_time": "2023-05-23T09:21:58.300848",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "for feature in features:\n",
    "    df[feature] = df[feature].fillna('') #filling all NaNs with blank string\n",
    "\n",
    "df[\"combined_features\"] = df.apply(combine_features,axis=1) #applying combined_features() method over each rows of dataframe and storing the combined string in \"combined_features\" column"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f52a4c1f",
   "metadata": {
    "papermill": {
     "duration": 0.010257,
     "end_time": "2023-05-23T09:21:58.541666",
     "exception": false,
     "start_time": "2023-05-23T09:21:58.531409",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Now that we have obtained the combined strings, we can now feed these strings to a CountVectorizer() object for getting the count matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1b75e02b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-23T09:21:58.564798Z",
     "iopub.status.busy": "2023-05-23T09:21:58.563535Z",
     "iopub.status.idle": "2023-05-23T09:21:58.757260Z",
     "shell.execute_reply": "2023-05-23T09:21:58.755898Z"
    },
    "papermill": {
     "duration": 0.208259,
     "end_time": "2023-05-23T09:21:58.760237",
     "exception": false,
     "start_time": "2023-05-23T09:21:58.551978",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "cv = CountVectorizer() #creating new CountVectorizer() object\n",
    "count_matrix = cv.fit_transform(df[\"combined_features\"]) #feeding combined strings(movie contents) to CountVectorizer() object"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4afc42cc",
   "metadata": {
    "papermill": {
     "duration": 0.009819,
     "end_time": "2023-05-23T09:21:58.781128",
     "exception": false,
     "start_time": "2023-05-23T09:21:58.771309",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "At this point, 60% work is done. Now, we need to obtain the cosine similarity matrix from the count matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "96a81276",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-23T09:21:58.804437Z",
     "iopub.status.busy": "2023-05-23T09:21:58.803108Z",
     "iopub.status.idle": "2023-05-23T09:21:59.496733Z",
     "shell.execute_reply": "2023-05-23T09:21:59.495278Z"
    },
    "papermill": {
     "duration": 0.708534,
     "end_time": "2023-05-23T09:21:59.499949",
     "exception": false,
     "start_time": "2023-05-23T09:21:58.791415",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "cosine_sim = cosine_similarity(count_matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9756c37d",
   "metadata": {
    "papermill": {
     "duration": 0.009858,
     "end_time": "2023-05-23T09:21:59.520160",
     "exception": false,
     "start_time": "2023-05-23T09:21:59.510302",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Now, we will define two helper functions to get movie title from movie index and vice-versa."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "25b15a00",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-23T09:21:59.543161Z",
     "iopub.status.busy": "2023-05-23T09:21:59.542734Z",
     "iopub.status.idle": "2023-05-23T09:21:59.549302Z",
     "shell.execute_reply": "2023-05-23T09:21:59.547946Z"
    },
    "papermill": {
     "duration": 0.021433,
     "end_time": "2023-05-23T09:21:59.551974",
     "exception": false,
     "start_time": "2023-05-23T09:21:59.530541",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_title_from_index(index):\n",
    "    return df[df.index == index][\"title\"].values[0]\n",
    "def get_index_from_title(title):\n",
    "    return df[df.title == title][\"index\"].values[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "607d3f4b",
   "metadata": {
    "papermill": {
     "duration": 0.010752,
     "end_time": "2023-05-23T09:21:59.572913",
     "exception": false,
     "start_time": "2023-05-23T09:21:59.562161",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Our next step is to get the title of the movie that the user currently likes. Then we will find the index of that movie. After that, we will access the row corresponding to this movie in the similarity matrix. Thus, we will get the similarity scores of all other movies from the current movie. Then we will enumerate through all the similarity scores of that movie to make a tuple of movie index and similarity score. This will convert a row of similarity scores like this- `[1 0.5 0.2 0.9]` to this- `[(0, 1) (1, 0.5) (2, 0.2) (3, 0.9)]` . Here, each item is in this form- (movie index, similarity score)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c0a4403e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-23T09:21:59.596603Z",
     "iopub.status.busy": "2023-05-23T09:21:59.595549Z",
     "iopub.status.idle": "2023-05-23T09:21:59.610547Z",
     "shell.execute_reply": "2023-05-23T09:21:59.609379Z"
    },
    "papermill": {
     "duration": 0.030345,
     "end_time": "2023-05-23T09:21:59.613772",
     "exception": false,
     "start_time": "2023-05-23T09:21:59.583427",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "movie_user_likes = \"Avatar\"\n",
    "movie_index = get_index_from_title(movie_user_likes)\n",
    "similar_movies = list(enumerate(cosine_sim[movie_index])) #accessing the row corresponding to given movie to find all the similarity scores for that movie and then enumerating over it"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa973ab7",
   "metadata": {
    "papermill": {
     "duration": 0.010171,
     "end_time": "2023-05-23T09:21:59.634190",
     "exception": false,
     "start_time": "2023-05-23T09:21:59.624019",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "\n",
    "Now comes the most vital point. We will sort the list `similar_movies` according to similarity scores in descending order. Since the most similar movie to a given movie will be itself, we will discard the first element after sorting the movies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c709224e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-23T09:21:59.657270Z",
     "iopub.status.busy": "2023-05-23T09:21:59.656523Z",
     "iopub.status.idle": "2023-05-23T09:21:59.664759Z",
     "shell.execute_reply": "2023-05-23T09:21:59.663619Z"
    },
    "papermill": {
     "duration": 0.022923,
     "end_time": "2023-05-23T09:21:59.667565",
     "exception": false,
     "start_time": "2023-05-23T09:21:59.644642",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "sorted_similar_movies = sorted(similar_movies,key=lambda x:x[1],reverse=True)[1:6]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a97fa8ed",
   "metadata": {
    "papermill": {
     "duration": 0.010195,
     "end_time": "2023-05-23T09:21:59.688099",
     "exception": false,
     "start_time": "2023-05-23T09:21:59.677904",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Now, we will run a loop to print first 5 entries from `sorted_similar_movies` list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e166f623",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-23T09:21:59.711152Z",
     "iopub.status.busy": "2023-05-23T09:21:59.710725Z",
     "iopub.status.idle": "2023-05-23T09:21:59.722590Z",
     "shell.execute_reply": "2023-05-23T09:21:59.721144Z"
    },
    "papermill": {
     "duration": 0.026158,
     "end_time": "2023-05-23T09:21:59.725178",
     "exception": false,
     "start_time": "2023-05-23T09:21:59.699020",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 5 similar movies to Avatar are:\n",
      "\n",
      "Guardians of the Galaxy\n",
      "Aliens\n",
      "Star Wars: Clone Wars: Volume 1\n",
      "Star Trek Into Darkness\n",
      "Star Trek Beyond\n"
     ]
    }
   ],
   "source": [
    "i=0\n",
    "print(\"Top 5 similar movies to \"+movie_user_likes+\" are:\\n\")\n",
    "for element in sorted_similar_movies:\n",
    "    print(get_title_from_index(element[0]))\n",
    "    i=i+1\n",
    "    if i>5:\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34defe86",
   "metadata": {
    "papermill": {
     "duration": 0.010376,
     "end_time": "2023-05-23T09:21:59.745858",
     "exception": false,
     "start_time": "2023-05-23T09:21:59.735482",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Home Work Solution"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e30127fc",
   "metadata": {
    "papermill": {
     "duration": 0.009902,
     "end_time": "2023-05-23T09:21:59.766919",
     "exception": false,
     "start_time": "2023-05-23T09:21:59.757017",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Let's Inspect the vote_average feature and check if there are any null values. Looks like it is clean."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "722824d4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-23T09:21:59.790910Z",
     "iopub.status.busy": "2023-05-23T09:21:59.789740Z",
     "iopub.status.idle": "2023-05-23T09:21:59.802342Z",
     "shell.execute_reply": "2023-05-23T09:21:59.801058Z"
    },
    "papermill": {
     "duration": 0.027156,
     "end_time": "2023-05-23T09:21:59.804844",
     "exception": false,
     "start_time": "2023-05-23T09:21:59.777688",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 7.2,  6.9,  6.3,  7.6,  6.1,  5.9,  7.4,  7.3,  5.7,  5.4,  7. ,\n",
       "        6.5,  6.4,  6.2,  7.1,  5.8,  6.6,  7.5,  5.5,  6.7,  6.8,  6. ,\n",
       "        5.1,  7.8,  5.6,  5.2,  8.2,  7.7,  5.3,  8. ,  4.8,  4.9,  7.9,\n",
       "        8.1,  4.7,  5. ,  4.2,  4.4,  4.1,  3.7,  3.6,  3. ,  3.9,  4.3,\n",
       "        4.5,  3.4,  4.6,  8.3,  3.5,  4. ,  2.3,  3.2,  0. ,  3.8,  2.9,\n",
       "        8.5,  1.9,  3.1,  3.3,  2.2,  0.5,  9.3,  8.4,  2.7, 10. ,  1. ,\n",
       "        2. ,  2.8,  9.5,  2.6,  2.4])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"vote_average\"].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32e8b6e5",
   "metadata": {
    "papermill": {
     "duration": 0.010043,
     "end_time": "2023-05-23T09:21:59.825636",
     "exception": false,
     "start_time": "2023-05-23T09:21:59.815593",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Now, we will again sort our sorted_similar_movies but this time with respect to vote_average. x[0] has the index of the movie in the data frame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e43f3d33",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-23T09:21:59.848328Z",
     "iopub.status.busy": "2023-05-23T09:21:59.847856Z",
     "iopub.status.idle": "2023-05-23T09:21:59.854815Z",
     "shell.execute_reply": "2023-05-23T09:21:59.853549Z"
    },
    "papermill": {
     "duration": 0.021376,
     "end_time": "2023-05-23T09:21:59.857444",
     "exception": false,
     "start_time": "2023-05-23T09:21:59.836068",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(3208, 0.3464101615137755), (94, 0.42339019740572564), (2403, 0.3774256780481986), (47, 0.34426518632954817), (56, 0.33596842045264647)]\n"
     ]
    }
   ],
   "source": [
    "sort_by_average_vote = sorted(sorted_similar_movies,key=lambda x:df[\"vote_average\"][x[0]],reverse=True)\n",
    "print(sort_by_average_vote)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "878f0668",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-23T09:21:59.881343Z",
     "iopub.status.busy": "2023-05-23T09:21:59.880862Z",
     "iopub.status.idle": "2023-05-23T09:21:59.892456Z",
     "shell.execute_reply": "2023-05-23T09:21:59.891152Z"
    },
    "papermill": {
     "duration": 0.026702,
     "end_time": "2023-05-23T09:21:59.895100",
     "exception": false,
     "start_time": "2023-05-23T09:21:59.868398",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Suggesting top 5 movies in order of Average Votes:\n",
      "\n",
      "Star Wars: Clone Wars: Volume 1\n",
      "Guardians of the Galaxy\n",
      "Aliens\n",
      "Star Trek Into Darkness\n",
      "Star Trek Beyond\n"
     ]
    }
   ],
   "source": [
    "i=0\n",
    "print(\"Suggesting top 5 movies in order of Average Votes:\\n\")\n",
    "for element in sort_by_average_vote:\n",
    "    print(get_title_from_index(element[0]))\n",
    "    i=i+1\n",
    "    if i>5:\n",
    "        break"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 18.494972,
   "end_time": "2023-05-23T09:22:00.729577",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2023-05-23T09:21:42.234605",
   "version": "2.4.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
